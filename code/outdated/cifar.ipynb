{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import pickle\n",
    "import gzip\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_split(X_train,y_train):\n",
    "    X_tr, y_tr = shuffle(X_train,y_train)\n",
    "    _, X_val, _, y_val = train_test_split(X_tr,y_tr,test_size=0.1)\n",
    "    return X_tr,y_tr,X_val,y_val\n",
    "\n",
    "def one_hot_encoding(train_labels,test_labels,num_classes):\n",
    "    lb = LabelEncoder()\n",
    "    train_labels = lb.fit_transform(train_labels)\n",
    "    test_labels = lb.fit_transform(test_labels)\n",
    "    train_label_ohc = []\n",
    "    test_label_ohc = []\n",
    "    for l in train_labels:\n",
    "            train_label_ohc.append(np.eye(num_classes)[l])\n",
    "    for l in test_labels:\n",
    "            test_label_ohc.append(np.eye(num_classes)[l])\n",
    "    return train_label_ohc,test_label_ohc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "\n",
    "class CIFAR10():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.path_to_dir = '../content/drive/MyDrive/datasets/cifar-10-batches-py'\n",
    "        self.meta_data = unpickle(self.path_to_dir + \"/batches.meta\")\n",
    "        images, labels, test_images, test_labels = self.__load()\n",
    "        self.__prepare_data(images,labels,test_images,test_labels)\n",
    "\n",
    "    def __load(self):\n",
    "        #num_cases_per_batch: 10000\n",
    "        #label_names': airplane,automobile,bird,cat,deer,dog,frog,horse,ship,truck\n",
    "        #num_vis: 3072\n",
    "        label_names = self.meta_data[b'label_names']\n",
    "        label_names = np.array(label_names)\n",
    "        data = []\n",
    "        labels = []\n",
    "        self.labels_ohc = []\n",
    "        for i in range(1,6):\n",
    "            #Data,filenames und label extrahieren\n",
    "            curr_batch = unpickle(self.path_to_dir + \"/data_batch_{}\".format(i))\n",
    "            #keys: b'batch_label', b'labels', b'data', b'filenames'\n",
    "        \n",
    "            data.append(curr_batch[b'data']) #shape: 10000,3072 -> 3,32,32\n",
    "            \n",
    "            labels += curr_batch[b'labels']\n",
    "        \n",
    "        cifar_test_batch = unpickle(self.path_to_dir + \"/test_batch\")\n",
    "        data.append(cifar_test_batch[b'data'])\n",
    "        labels += cifar_test_batch[b'labels']\n",
    "                \n",
    "        #Formatierung der Liste in 3,32,32 das nn mit den Daten arbeiten kann\n",
    "        data = np.reshape(data,(len(data[0])*6,3072))\n",
    "        data = data.reshape(len(data),3,32,32)\n",
    "        data = np.rollaxis(data, 1, 4)\n",
    "        train_data = data[0:50000]\n",
    "        train_labels = labels[0:50000]\n",
    "        test_data = data[50000:]\n",
    "        test_labels = labels[50000:]\n",
    "        return train_data,train_labels,test_data,test_labels\n",
    "    \n",
    "    def __prepare_data(self,train_data,train_labels,X_test,test_labels):\n",
    "        train_lb,y_test = one_hot_encoding(train_labels,test_labels,10)\n",
    "        X_train,y_train,X_val,y_val = train_validate_split(train_data,train_lb)\n",
    "        \n",
    "        self.dict_images = {'X_train':X_train,\n",
    "                            'X_test': X_test,\n",
    "                            'X_val': X_val,\n",
    "                        }\n",
    "        self.dict_labels = {'y_train': y_train,\n",
    "                            'y_test': y_test,\n",
    "                            'y_val': y_val\n",
    "                        }\n",
    "\n",
    "    def get_data(self,what_is_needed):\n",
    "        if what_is_needed == 'train':\n",
    "            return (self.dict_images['X_train'],self.dict_labels['y_train'])\n",
    "        elif what_is_needed == 'test':\n",
    "            return (self.dict_images['X_test'],self.dict_labels['y_test'])\n",
    "        elif what_is_needed == 'val':\n",
    "            return (self.dict_images['X_val'],self.dict_labels['y_val'])\n",
    "        elif what_is_needed == 'all':\n",
    "            return (self.dict_images,self.dict_labels)\n",
    "          \n",
    "    def print_data(self):\n",
    "\n",
    "        plot, ax = plt.subplots(3,3)\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                idx = np.random.randint(0,self.X_train.shape[0])\n",
    "\n",
    "                ax[i,j].imshow(self.X_train[idx])\n",
    "                ax[i,j].set_xlabel(self.y_train[idx])\n",
    "                ax[i,j].get_yaxis().set_visible(False)\n",
    "        plt.show()\n",
    "\n",
    "    def get_mean_std(self):\n",
    "        mean = [0.49139968, 0.48215841, 0.44653091]\n",
    "        std =  [0.2469767,  0.24336646, 0.26144247]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import normalize\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "class CIFAR10():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.LABELS = {b'airplane':0, b'automobile':1, b'bird':2, b'cat':3, b'deer':4, b'dog':5, b'frog':6, b'horse':7,\n",
    " b'ship':8, b'truck':9}\n",
    "        self.path_to_dir = '../files/cifar-10-batches-py'\n",
    "        self.meta_data = unpickle(self.path_to_dir + \"/batches.meta\")\n",
    "\n",
    "        self.X_train,self.y_train,self.X_test,self.y_test = \\\n",
    "            self.__load()\n",
    "\n",
    "\n",
    "    def __load(self):\n",
    "        #num_cases_per_batch: 10000\n",
    "        #label_names': airplane,automobile,bird,cat,deer,dog,frog,horse,ship,truck\n",
    "        #num_vis: 3072\n",
    "        label_names = self.meta_data[b'label_names']\n",
    "        label_names = np.array(label_names)\n",
    "        data = []\n",
    "        labels = []\n",
    "        self.labels_ohc = []\n",
    "        for i in range(1,6):\n",
    "            #Data,filenames und label extrahieren\n",
    "            curr_batch = unpickle(self.path_to_dir + \"/data_batch_{}\".format(i))\n",
    "            #keys: b'batch_label', b'labels', b'data', b'filenames'\n",
    "        \n",
    "            data.append(curr_batch[b'data']) #shape: 10000,3072 -> 3,32,32\n",
    "            \n",
    "            labels += curr_batch[b'labels']\n",
    "        \n",
    "        cifar_test_batch = unpickle(self.path_to_dir + \"/test_batch\")\n",
    "        data.append(cifar_test_batch[b'data'])\n",
    "        labels += cifar_test_batch[b'labels']\n",
    "\n",
    "        for l in labels:\n",
    "            self.labels_ohc.append(np.eye(10)[l])\n",
    "        \n",
    "        #Formatierung der Liste in 3,32,32 das nn mit den Daten arbeiten kann\n",
    "        data = np.reshape(data,(len(data[0])*6,3072))\n",
    "        data = data.reshape(len(data),3,32,32)\n",
    "        data = np.rollaxis(data, 1, 4)\n",
    "        train_data = data[0:50000]\n",
    "        train_labels = self.labels_ohc[0:50000]\n",
    "        test_data = data[50000:]\n",
    "        test_labels = self.labels_ohc[50000:]\n",
    "\n",
    "        return train_data,train_labels,test_data,test_labels\n",
    "    \n",
    "    def get_data(self):\n",
    "        return self.X_train,self.y_train,self.X_test,self.y_test\n",
    "           \n",
    "    def print_data(self):\n",
    "\n",
    "        plot, ax = plt.subplots(3,3)\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                idx = np.random.randint(0,self.X_train.shape[0])\n",
    "\n",
    "                ax[i,j].imshow(self.X_train[idx])\n",
    "                ax[i,j].set_xlabel(self.y_train[idx])\n",
    "                ax[i,j].get_yaxis().set_visible(False)\n",
    "        plt.show()\n",
    "\n",
    "    def get_mean_std(self):\n",
    "        mean = [0.49139968, 0.48215841, 0.44653091]\n",
    "        std =  [0.2469767,  0.24336646, 0.26144247]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../files/cifar-10-batches-py/batches.meta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mg:\\ba\\activation-ba\\code\\outdated\\cifar.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/ba/activation-ba/code/outdated/cifar.ipynb#ch0000006?line=0'>1</a>\u001b[0m cif \u001b[39m=\u001b[39m CIFAR10()\n",
      "\u001b[1;32mg:\\ba\\activation-ba\\code\\outdated\\cifar.ipynb Cell 4'\u001b[0m in \u001b[0;36mCIFAR10.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/ba/activation-ba/code/outdated/cifar.ipynb#ch0000005?line=9'>10</a>\u001b[0m        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLABELS \u001b[39m=\u001b[39m {\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mairplane\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m0\u001b[39m, \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mautomobile\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m1\u001b[39m, \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbird\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m2\u001b[39m, \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcat\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m3\u001b[39m, \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdeer\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m4\u001b[39m, \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdog\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m5\u001b[39m, \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfrog\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m6\u001b[39m, \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhorse\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m7\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/ba/activation-ba/code/outdated/cifar.ipynb#ch0000005?line=10'>11</a>\u001b[0m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mship\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m8\u001b[39m, \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtruck\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m9\u001b[39m}\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/ba/activation-ba/code/outdated/cifar.ipynb#ch0000005?line=11'>12</a>\u001b[0m        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath_to_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../files/cifar-10-batches-py\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/ba/activation-ba/code/outdated/cifar.ipynb#ch0000005?line=12'>13</a>\u001b[0m        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta_data \u001b[39m=\u001b[39m unpickle(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath_to_dir \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m/batches.meta\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/ba/activation-ba/code/outdated/cifar.ipynb#ch0000005?line=14'>15</a>\u001b[0m        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_train,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_train,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_test,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_test \u001b[39m=\u001b[39m \\\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/ba/activation-ba/code/outdated/cifar.ipynb#ch0000005?line=15'>16</a>\u001b[0m            \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__load()\n",
      "\u001b[1;32mg:\\ba\\activation-ba\\code\\outdated\\cifar.ipynb Cell 4'\u001b[0m in \u001b[0;36munpickle\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/ba/activation-ba/code/outdated/cifar.ipynb#ch0000005?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munpickle\u001b[39m(file):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/ba/activation-ba/code/outdated/cifar.ipynb#ch0000005?line=2'>3</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(file, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m fo:\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/ba/activation-ba/code/outdated/cifar.ipynb#ch0000005?line=3'>4</a>\u001b[0m         \u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(fo, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbytes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/ba/activation-ba/code/outdated/cifar.ipynb#ch0000005?line=4'>5</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mdict\u001b[39m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../files/cifar-10-batches-py/batches.meta'"
     ]
    }
   ],
   "source": [
    "cif = CIFAR10()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Custom Dataset and assign X_train and X_test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.transforms import ToPILImage\n",
    "import numpy as np\n",
    "from sympy import Ci\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Cifar10Dataset():\n",
    "    def __init__(self,images,labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = T.Compose([\n",
    "            T.ToTensor()\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        if self.transform:\n",
    "            images = self.transform(self.images[idx])\n",
    "            normalize = T.Normalize( [0.49139968, 0.48215841, 0.44653091],[0.2469767,  0.24336646, 0.26144247])\n",
    "            norm = normalize(images)\n",
    "            images = norm\n",
    "        return (images,self.labels[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load split data into dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#epoche 15: 0.1 lr 0.1\n",
    "'''class CNN_CIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_CIFAR,self).__init__()\n",
    "        #conv layers\n",
    "        self.conv1 = nn.Conv2d(3,32,3,1)\n",
    "\n",
    "        #fc layers\n",
    "        self.fc1 = nn.Linear(28800,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "      x = F.relu(self.conv1(x))\n",
    "      x = x.reshape(x.shape[0],-1)\n",
    "      x = self.fc1(x)\n",
    "      return x'''\n",
    "# Train acc: 0.93006 Train loss: 0.21952689442121304 lr 0.001\n",
    "'''class CNN_CIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_CIFAR,self).__init__()\n",
    "        #conv layers\n",
    "        self.conv1 = nn.Conv2d(3,128,3,1)\n",
    "\n",
    "        #fc layers\n",
    "        self.fc1 = nn.Linear(115200,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "      x = F.relu(self.conv1(x))\n",
    "      x = x.reshape(x.shape[0],-1)\n",
    "      x = self.fc1(x)\n",
    "      return x'''\n",
    "# acc: 0.91088 Train loss: 0.2775786456513608 lr 0.001\n",
    "'''class CNN_CIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_CIFAR,self).__init__()\n",
    "        #conv layers\n",
    "        self.conv1 = nn.Conv2d(3,64,3,1)\n",
    "\n",
    "        #fc layers\n",
    "        self.fc1 = nn.Linear(57600,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "      x = F.relu(self.conv1(x))\n",
    "      x = x.reshape(x.shape[0],-1)\n",
    "      x = self.fc1(x)\n",
    "      return x'''\n",
    "#Train acc: 0.939 Train loss: 0.18734320437258764 lr 0.001\n",
    "'''class CNN_CIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_CIFAR,self).__init__()\n",
    "        #conv layers\n",
    "        self.conv1 = nn.Conv2d(3,128,5,1)\n",
    "\n",
    "        #fc layers\n",
    "        self.fc1 = nn.Linear(25088,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "      x = F.relu(self.conv1(x))\n",
    "      x = x.reshape(x.shape[0],-1)\n",
    "      x = self.fc1(x)\n",
    "      return x\n",
    "'''\n",
    "#Train acc: 0.82806 Train loss: 0.5260674791708588 lr 0.0003\n",
    "'''class CNN_CIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_CIFAR,self).__init__()\n",
    "        #conv layers\n",
    "        self.conv1 = nn.Conv2d(3,128,5,1)\n",
    "        self.conv2 = nn.Conv2d(128,32,3,1)\n",
    "\n",
    "        #fc layers\n",
    "        self.fc1 = nn.Linear(21632,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "      x = F.relu(self.conv1(x))\n",
    "      x = F.relu(self.conv2(x))\n",
    "      x = x.reshape(x.shape[0],-1)\n",
    "      x = self.fc1(x)\n",
    "      return x'''\n",
    "#Train acc: 0.97834 Train loss: 0.07318448818677437 lr 0.0003\n",
    "'''class CNN_CIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_CIFAR,self).__init__()\n",
    "        #conv layers\n",
    "        self.conv1 = nn.Conv2d(3,128,5,1)\n",
    "        self.conv2 = nn.Conv2d(128,64,3,1)\n",
    "\n",
    "        #fc layers\n",
    "        self.fc1 = nn.Linear(43264,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "      x = F.relu(self.conv1(x))\n",
    "      x = F.relu(self.conv2(x))\n",
    "      x = x.reshape(x.shape[0],-1)\n",
    "      x = self.fc1(x)\n",
    "      return x'''\n",
    "#Train acc: 0.977 Train loss: 0.06664528534313287 lr 0.001\n",
    "'''class CNN_CIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_CIFAR,self).__init__()\n",
    "        #conv layers\n",
    "        self.conv1 = nn.Conv2d(3,64,3,1)\n",
    "        self.conv2 = nn.Conv2d(64,32,3,1)\n",
    "        #fc layers\n",
    "        self.fc1 = nn.Linear(25088,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "      x = F.relu(self.conv1(x))\n",
    "      x = F.relu(self.conv2(x))\n",
    "      x = x.reshape(x.shape[0],-1)\n",
    "      x = self.fc1(x)\n",
    "      return x'''\n",
    "#Train acc: 0.89956 Train loss: 0.33078178741363196\n",
    "'''class CNN_CIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_CIFAR,self).__init__()\n",
    "        #conv layers\n",
    "        self.conv1 = nn.Conv2d(3,16,3,1)\n",
    "\n",
    "        #fc layers\n",
    "        self.fc1 = nn.Linear(14400,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "      x = F.relu(self.conv1(x))\n",
    "      x = x.reshape(x.shape[0],-1)\n",
    "      x = self.fc1(x)\n",
    "      return x'''\n",
    "#Train acc: 0.87052 Train loss: 0.39550972418221986\n",
    "class CNN_CIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_CIFAR,self).__init__()\n",
    "        #conv layers\n",
    "        self.conv1 = nn.Conv2d(3,32,3,1)\n",
    "\n",
    "        #fc layers\n",
    "        self.fc1 = nn.Linear(28800,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "      x = F.relu(self.conv1(x))\n",
    "      x = x.reshape(x.shape[0],-1)\n",
    "      x = self.fc1(x)\n",
    "      return x\n",
    "\n",
    "class CNN_CIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_CIFAR,self).__init__()\n",
    "        #conv layers\n",
    "        self.conv1 = nn.Conv2d(3,64,3,1)\n",
    "        self.conv2 = nn.Conv2d(64,32,5,1)\n",
    "        #fc layers\n",
    "        self.fc1 = nn.Linear(21632,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "      x = F.relu(self.conv1(x))\n",
    "      x = F.relu(self.conv2(x))\n",
    "      x = x.reshape(x.shape[0],-1)\n",
    "      x = self.fc1(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "model = CNN_CIFAR()\n",
    "model.to('cuda')\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([ 0.2279, -0.2810, -0.0056])\n",
      "tensor([0.8466, 1.3092, 1.3283])\n",
      "tensor([0.7168, 1.7141, 1.7643])\n",
      "tensor([-0.6809, -0.0990,  0.6998])\n",
      "tensor([0.3697, 0.3027, 0.2945])\n",
      "tensor([0.1367, 0.0917, 0.0867])\n",
      "tensor([-0.9863, -0.9208, -1.1283])\n",
      "tensor([0.6548, 0.6276, 0.5527])\n",
      "tensor([0.4287, 0.3939, 0.3054])\n",
      "tensor([0.0808, 0.2837, 0.4689])\n",
      "tensor([0.8243, 0.7789, 0.7609])\n",
      "tensor([0.6795, 0.6067, 0.5789])\n",
      "tensor([0.8842, 0.4340, 0.5502])\n",
      "tensor([1.0051, 1.3289, 1.2280])\n",
      "tensor([1.0103, 1.7660, 1.5081])\n",
      "tensor([-0.4335, -0.7780, -0.7654])\n",
      "tensor([0.3868, 0.2660, 0.2496])\n",
      "tensor([0.1496, 0.0708, 0.0623])\n",
      "tensor([-0.4240, -0.4888, -0.7233])\n",
      "tensor([1.2266, 1.1415, 0.9637])\n",
      "tensor([1.5045, 1.3029, 0.9288])\n",
      "tensor([0.9653, 1.0176, 1.0835])\n",
      "tensor([0.7412, 0.7522, 0.7002])\n",
      "tensor([0.5493, 0.5658, 0.4902])\n",
      "tensor([ 0.2901, -0.1079, -0.1016])\n",
      "tensor([1.1283, 1.2103, 0.9229])\n",
      "tensor([1.2732, 1.4648, 0.8517])\n",
      "tensor([-0.6896, -0.6413, -0.1671])\n",
      "tensor([0.4471, 0.5367, 0.4135])\n",
      "tensor([0.1999, 0.2880, 0.1710])\n",
      "tensor([-0.3744, -0.3298, -0.2760])\n",
      "tensor([1.0826, 1.1064, 1.0423])\n",
      "tensor([1.1720, 1.2241, 1.0863])\n",
      "tensor([ 0.1922, -0.1127, -0.2791])\n",
      "tensor([0.9957, 1.1102, 1.1324])\n",
      "tensor([0.9915, 1.2325, 1.2823])\n",
      "tensor([0.8189, 0.9010, 0.9909])\n",
      "tensor([0.5326, 0.5870, 0.7020])\n",
      "tensor([0.2837, 0.3446, 0.4928])\n",
      "tensor([-0.2732, -0.3877, -0.3602])\n",
      "tensor([1.1326, 1.1419, 1.1333])\n",
      "tensor([1.2829, 1.3039, 1.2844])\n",
      "tensor([0.3562, 0.5489, 0.1162])\n",
      "tensor([1.3226, 1.4598, 0.9388])\n",
      "tensor([1.7492, 2.1309, 0.8814])\n",
      "tensor([0.8425, 0.7393, 0.4907])\n",
      "tensor([0.9210, 0.8894, 0.7585])\n",
      "tensor([0.8482, 0.7911, 0.5754])\n",
      "tensor([-0.0426,  0.1369,  0.1284])\n",
      "tensor([1.0224, 1.0030, 0.9466])\n",
      "tensor([1.0452, 1.0060, 0.8960])\n",
      "tensor([-1.3227, -1.4346, -1.1778])\n",
      "tensor([0.7564, 0.7064, 0.6858])\n",
      "tensor([0.5721, 0.4990, 0.4703])\n",
      "tensor([-0.2721, -0.1897, -0.7258])\n",
      "tensor([0.8572, 0.8460, 0.5696])\n",
      "tensor([0.7348, 0.7157, 0.3245])\n",
      "tensor([0.1382, 0.2615, 0.3614])\n",
      "tensor([0.8308, 0.7442, 0.7883])\n",
      "tensor([0.6902, 0.5539, 0.6214])\n",
      "tensor([0.1834, 0.2341, 0.3267])\n",
      "tensor([1.1570, 1.1405, 1.0472])\n",
      "tensor([1.3386, 1.3007, 1.0967])\n",
      "tensor([ 0.1482, -0.1644, -0.2211])\n",
      "tensor([0.7566, 0.8120, 0.6223])\n",
      "tensor([0.5725, 0.6594, 0.3873])\n",
      "tensor([-0.8423, -0.8526, -0.5869])\n",
      "tensor([0.9751, 0.9667, 0.8542])\n",
      "tensor([0.9509, 0.9345, 0.7296])\n",
      "tensor([-0.2156, -0.5290, -0.4396])\n",
      "tensor([1.4262, 1.2683, 1.0481])\n",
      "tensor([2.0341, 1.6086, 1.0986])\n",
      "tensor([-0.6423, -0.7781, -0.4723])\n",
      "tensor([0.9958, 0.8591, 0.7391])\n",
      "tensor([0.9916, 0.7380, 0.5463])\n",
      "tensor([0.3574, 0.3789, 0.2266])\n",
      "tensor([0.4256, 0.3955, 0.5435])\n",
      "tensor([0.1812, 0.1564, 0.2954])\n",
      "tensor([0.5937, 0.4759, 0.3249])\n",
      "tensor([1.0710, 1.1240, 0.8641])\n",
      "tensor([1.1470, 1.2634, 0.7467])\n",
      "tensor([0.4211, 0.5607, 0.8170])\n",
      "tensor([0.6429, 0.6801, 0.5661])\n",
      "tensor([0.4133, 0.4625, 0.3205])\n",
      "tensor([-0.2275, -0.3935, -0.4553])\n",
      "tensor([1.0769, 1.0471, 0.9459])\n",
      "tensor([1.1597, 1.0963, 0.8947])\n",
      "tensor([ 0.4325, -0.1032, -0.0659])\n",
      "tensor([0.6617, 0.9999, 0.8518])\n",
      "tensor([0.4379, 0.9998, 0.7255])\n",
      "tensor([0.7575, 0.3119, 0.0418])\n",
      "tensor([0.8354, 1.0652, 1.3160])\n",
      "tensor([0.6979, 1.1347, 1.7319])\n",
      "tensor([-0.4055, -0.5544, -0.3660])\n",
      "tensor([0.9151, 0.8402, 0.7009])\n",
      "tensor([0.8374, 0.7059, 0.4913])\n",
      "tensor([-0.1048, -0.2920, -0.3263])\n",
      "tensor([0.8978, 1.1517, 1.2330])\n",
      "tensor([0.8060, 1.3264, 1.5203])\n",
      "tensor([0.8328, 0.9241, 1.0670])\n",
      "tensor([0.8466, 0.8585, 0.8117])\n",
      "tensor([0.7167, 0.7370, 0.6588])\n",
      "tensor([0.3695, 0.6535, 0.8260])\n",
      "tensor([0.8662, 0.8422, 0.7959])\n",
      "tensor([0.7503, 0.7094, 0.6334])\n",
      "tensor([ 0.1840, -0.2649, -0.1936])\n",
      "tensor([0.8293, 1.0004, 1.0034])\n",
      "tensor([0.6878, 1.0007, 1.0068])\n",
      "tensor([-0.7862, -0.5649, -0.3267])\n",
      "tensor([1.0920, 1.0390, 0.8992])\n",
      "tensor([1.1926, 1.0795, 0.8087])\n",
      "tensor([0.1955, 0.1141, 0.2145])\n",
      "tensor([1.0143, 0.9667, 0.8528])\n",
      "tensor([1.0288, 0.9345, 0.7272])\n",
      "tensor([-0.1740,  0.2190, -0.9603])\n",
      "tensor([0.4826, 0.4963, 0.4432])\n",
      "tensor([0.2329, 0.2464, 0.1964])\n",
      "tensor([ 0.2727, -0.0539, -0.0519])\n",
      "tensor([0.8394, 1.0074, 0.9997])\n",
      "tensor([0.7045, 1.0149, 0.9994])\n",
      "tensor([0.5995, 0.8101, 0.7840])\n",
      "tensor([1.1979, 1.1743, 1.2377])\n",
      "tensor([1.4350, 1.3789, 1.5320])\n",
      "tensor([1.1560, 1.2076, 1.2486])\n",
      "tensor([1.0568, 1.0755, 1.0113])\n",
      "tensor([1.1168, 1.1568, 1.0228])\n",
      "tensor([ 0.0028,  0.0542, -0.4700])\n",
      "tensor([0.6161, 0.5773, 0.5888])\n",
      "tensor([0.3796, 0.3332, 0.3467])\n",
      "tensor([ 0.0479,  0.1414, -0.3916])\n",
      "tensor([0.6082, 0.7619, 0.5800])\n",
      "tensor([0.3699, 0.5804, 0.3364])\n",
      "tensor([-0.0812,  0.0543,  0.1973])\n",
      "tensor([0.8430, 0.8565, 1.0499])\n",
      "tensor([0.7106, 0.7336, 1.1024])\n",
      "tensor([0.3588, 0.4142, 0.5308])\n",
      "tensor([1.4604, 1.4907, 1.3456])\n",
      "tensor([2.1328, 2.2223, 1.8108])\n",
      "tensor([-0.5601, -0.4979, -0.2103])\n",
      "tensor([1.0899, 1.0650, 1.0162])\n",
      "tensor([1.1880, 1.1342, 1.0326])\n",
      "tensor([0.4513, 0.2566, 0.0138])\n",
      "tensor([0.8283, 0.8427, 0.9510])\n",
      "tensor([0.6860, 0.7101, 0.9044])\n",
      "tensor([-0.0886,  0.0841,  0.1414])\n",
      "tensor([0.7898, 0.8296, 0.8945])\n",
      "tensor([0.6238, 0.6883, 0.8001])\n",
      "tensor([-0.0870,  0.0372,  0.0210])\n",
      "tensor([0.8022, 0.7839, 0.8702])\n",
      "tensor([0.6435, 0.6145, 0.7573])\n",
      "tensor([0.6313, 0.6964, 0.6414])\n",
      "tensor([0.7588, 0.7998, 0.8326])\n",
      "tensor([0.5758, 0.6396, 0.6933])\n",
      "tensor([0.6004, 0.6473, 0.7388])\n",
      "tensor([0.7137, 0.7243, 0.6742])\n",
      "tensor([0.5094, 0.5246, 0.4546])\n",
      "tensor([-0.1758, -0.1403,  0.0056])\n",
      "tensor([0.9153, 0.9289, 0.8647])\n",
      "tensor([0.8378, 0.8628, 0.7476])\n",
      "tensor([0.3038, 0.5563, 0.4194])\n",
      "tensor([1.3088, 1.2342, 1.2437])\n",
      "tensor([1.7129, 1.5231, 1.5468])\n",
      "tensor([0.8643, 0.9151, 0.9881])\n",
      "tensor([1.1364, 1.1532, 1.0735])\n",
      "tensor([1.2914, 1.3300, 1.1524])\n",
      "tensor([-0.0447,  0.0486,  0.3290])\n",
      "tensor([0.8970, 0.8670, 0.8142])\n",
      "tensor([0.8045, 0.7518, 0.6629])\n",
      "tensor([-0.3492, -0.4612, -0.5078])\n",
      "tensor([1.1724, 1.0437, 0.8465])\n",
      "tensor([1.3744, 1.0894, 0.7166])\n",
      "tensor([ 0.2517, -0.0699,  0.0922])\n",
      "tensor([0.9683, 1.0365, 0.9538])\n",
      "tensor([0.9377, 1.0743, 0.9098])\n",
      "tensor([-0.1918,  0.0487,  0.5530])\n",
      "tensor([0.8152, 0.7458, 0.5919])\n",
      "tensor([0.6645, 0.5561, 0.3504])\n",
      "tensor([-0.2695, -0.6975, -0.4031])\n",
      "tensor([0.9174, 0.7694, 0.6869])\n",
      "tensor([0.8416, 0.5920, 0.4719])\n",
      "tensor([-0.6860, -1.0494, -1.0610])\n",
      "tensor([0.7183, 0.6540, 0.5325])\n",
      "tensor([0.5159, 0.4277, 0.2835])\n",
      "tensor([-0.5936, -0.4095, -0.1611])\n",
      "tensor([0.5752, 0.5038, 0.5776])\n",
      "tensor([0.3308, 0.2538, 0.3337])\n",
      "tensor([0.1055, 0.0604, 0.1483])\n",
      "tensor([0.8615, 0.8423, 0.7917])\n",
      "tensor([0.7422, 0.7095, 0.6268])\n",
      "tensor([-0.2768, -0.2191, -0.2841])\n",
      "tensor([0.9835, 0.9283, 0.8889])\n",
      "tensor([0.9673, 0.8617, 0.7901])\n",
      "tensor([-0.1993, -0.7355, -0.9556])\n",
      "tensor([0.6722, 0.5269, 0.2952])\n",
      "tensor([0.4519, 0.2776, 0.0872])\n",
      "tensor([1.3799, 1.3328, 1.2748])\n",
      "tensor([1.0374, 1.2090, 1.2295])\n",
      "tensor([1.0763, 1.4617, 1.5116])\n",
      "tensor([-0.3301, -0.2404, -0.0540])\n",
      "tensor([1.1553, 1.2173, 1.1252])\n",
      "tensor([1.3346, 1.4817, 1.2662])\n",
      "tensor([-0.5875, -0.5458, -0.8895])\n",
      "tensor([0.5635, 0.6919, 0.4839])\n",
      "tensor([0.3176, 0.4787, 0.2341])\n",
      "tensor([-0.5481, -0.0674,  0.1693])\n",
      "tensor([0.7260, 0.5761, 0.4493])\n",
      "tensor([0.5270, 0.3319, 0.2019])\n",
      "tensor([0.4924, 0.5681, 0.4642])\n",
      "tensor([0.6602, 0.7124, 0.6313])\n",
      "tensor([0.4359, 0.5074, 0.3986])\n",
      "tensor([-0.5670, -0.6599, -0.6642])\n",
      "tensor([1.0205, 1.0658, 1.0415])\n",
      "tensor([1.0414, 1.1360, 1.0847])\n",
      "tensor([1.0827, 1.1662, 0.9722])\n",
      "tensor([0.5780, 0.6948, 0.9811])\n",
      "tensor([0.3341, 0.4827, 0.9625])\n",
      "tensor([0.0457, 0.2212, 0.0252])\n",
      "tensor([0.6605, 0.6792, 0.6678])\n",
      "tensor([0.4362, 0.4613, 0.4460])\n",
      "tensor([-0.5089, -0.6928, -0.7838])\n",
      "tensor([1.1219, 1.0953, 0.8060])\n",
      "tensor([1.2588, 1.1997, 0.6496])\n",
      "tensor([ 0.2494,  0.5923, -0.2523])\n",
      "tensor([0.9698, 1.0944, 0.7090])\n",
      "tensor([0.9404, 1.1977, 0.5027])\n",
      "tensor([-0.1381, -0.4885, -0.6391])\n",
      "tensor([1.0106, 0.9627, 0.8953])\n",
      "tensor([1.0213, 0.9268, 0.8015])\n",
      "tensor([0.1444, 0.3395, 0.0341])\n",
      "tensor([0.5897, 0.5702, 0.4469])\n",
      "tensor([0.3478, 0.3252, 0.1997])\n",
      "tensor([-1.1962, -1.1155, -1.2468])\n",
      "tensor([0.7539, 0.8042, 0.4326])\n",
      "tensor([0.5684, 0.6467, 0.1872])\n",
      "tensor([-0.4471, -0.3373, -0.7215])\n",
      "tensor([0.7253, 0.6605, 0.7550])\n",
      "tensor([0.5260, 0.4362, 0.5701])\n",
      "tensor([-0.6101, -0.4009, -0.2009])\n",
      "tensor([1.0445, 1.0028, 0.9618])\n",
      "tensor([1.0909, 1.0056, 0.9250])\n",
      "tensor([-0.4634, -0.3237, -0.1237])\n",
      "tensor([0.9874, 1.0637, 1.0465])\n",
      "tensor([0.9749, 1.1315, 1.0951])\n",
      "tensor([-1.0112, -1.1579, -1.1500])\n",
      "tensor([0.7424, 0.6168, 0.4983])\n",
      "tensor([0.5512, 0.3805, 0.2483])\n",
      "tensor([-0.2418, -0.2195, -0.3917])\n",
      "tensor([0.8905, 0.9055, 0.7462])\n",
      "tensor([0.7930, 0.8199, 0.5568])\n",
      "tensor([1.0657, 0.7412, 0.8851])\n",
      "tensor([0.7007, 0.8292, 0.7795])\n",
      "tensor([0.4909, 0.6875, 0.6076])\n",
      "tensor([-0.6665, -0.1702,  0.3283])\n",
      "tensor([0.5351, 0.5231, 0.5993])\n",
      "tensor([0.2864, 0.2737, 0.3592])\n",
      "tensor([0.2760, 0.0859, 0.0674])\n",
      "tensor([0.8163, 0.8743, 0.7564])\n",
      "tensor([0.6663, 0.7643, 0.5721])\n",
      "tensor([-0.3127, -0.6495, -0.4524])\n",
      "tensor([0.7057, 0.7396, 0.6258])\n",
      "tensor([0.4980, 0.5470, 0.3917])\n",
      "tensor([ 0.2654, -0.0647, -0.3283])\n",
      "tensor([0.6269, 0.6235, 0.5507])\n",
      "tensor([0.3931, 0.3888, 0.3033])\n",
      "tensor([-0.6024, -0.6208, -0.5428])\n",
      "tensor([0.7435, 0.7652, 0.7049])\n",
      "tensor([0.5527, 0.5856, 0.4968])\n",
      "tensor([-0.4867, -0.3423, -0.3323])\n",
      "tensor([0.7168, 0.7163, 0.6992])\n",
      "tensor([0.5139, 0.5131, 0.4889])\n",
      "tensor([-0.5856, -0.9281, -0.9129])\n",
      "tensor([0.8020, 0.8552, 0.7394])\n",
      "tensor([0.6433, 0.7314, 0.5467])\n",
      "tensor([-0.0157,  0.1265, -0.1637])\n",
      "tensor([1.0289, 1.0077, 1.2712])\n",
      "tensor([1.0586, 1.0155, 1.6160])\n",
      "tensor([-0.2680, -0.2135, -0.2323])\n",
      "tensor([0.5374, 0.5418, 0.5534])\n",
      "tensor([0.2888, 0.2936, 0.3063])\n",
      "tensor([0.7711, 0.4219, 0.1877])\n",
      "tensor([0.8608, 0.9160, 0.9249])\n",
      "tensor([0.7409, 0.8391, 0.8554])\n",
      "tensor([-0.8076, -0.7817, -0.5913])\n",
      "tensor([0.9158, 0.9293, 0.8651])\n",
      "tensor([0.8386, 0.8637, 0.7484])\n",
      "tensor([-0.3672, -0.5818, -0.3739])\n",
      "tensor([1.2689, 1.2667, 1.2880])\n",
      "tensor([1.6101, 1.6045, 1.6591])\n",
      "tensor([-0.9402, -0.8776, -0.9774])\n",
      "tensor([1.0379, 0.9492, 0.7047])\n",
      "tensor([1.0773, 0.9010, 0.4966])\n",
      "tensor([-0.1729, -0.4547, -0.1241])\n",
      "tensor([1.1388, 1.0827, 1.1858])\n",
      "tensor([1.2968, 1.1721, 1.4061])\n",
      "tensor([-0.1575, -0.0360, -0.0884])\n",
      "tensor([0.7871, 0.8449, 0.8435])\n",
      "tensor([0.6195, 0.7139, 0.7115])\n",
      "tensor([-0.1886, -0.1099,  0.0096])\n",
      "tensor([0.9244, 0.9901, 0.9562])\n",
      "tensor([0.8545, 0.9803, 0.9143])\n",
      "tensor([-0.0685, -0.5407, -0.7065])\n",
      "tensor([0.7662, 0.5276, 0.3366])\n",
      "tensor([0.5871, 0.2784, 0.1133])\n",
      "tensor([-0.0434, -0.1593, -0.3355])\n",
      "tensor([1.1996, 1.1022, 0.9685])\n",
      "tensor([1.4389, 1.2148, 0.9381])\n",
      "tensor([-0.4459, -0.4919, -0.4758])\n",
      "tensor([1.3421, 1.3183, 1.1249])\n",
      "tensor([1.8012, 1.7380, 1.2655])\n",
      "tensor([-0.4109, -0.1802, -0.7750])\n",
      "tensor([0.7745, 0.8670, 0.4730])\n",
      "tensor([0.5998, 0.7516, 0.2237])\n",
      "tensor([-0.0389, -0.2229, -1.1623])\n",
      "tensor([0.6014, 0.5249, 0.3804])\n",
      "tensor([0.3617, 0.2755, 0.1447])\n",
      "tensor([0.0563, 0.1961, 0.0472])\n",
      "tensor([0.9970, 1.0292, 1.0615])\n",
      "tensor([0.9939, 1.0592, 1.1268])\n",
      "tensor([-0.1252,  0.0715,  0.0926])\n",
      "tensor([0.6093, 0.6999, 0.5695])\n",
      "tensor([0.3713, 0.4898, 0.3244])\n",
      "tensor([-0.6437, -0.7848, -0.7183])\n",
      "tensor([0.8122, 0.8407, 0.8016])\n",
      "tensor([0.6597, 0.7067, 0.6426])\n",
      "tensor([0.1838, 0.4809, 0.7272])\n",
      "tensor([0.9726, 1.1532, 1.0997])\n",
      "tensor([0.9459, 1.3299, 1.2093])\n",
      "tensor([-0.2689, -0.1871, -0.2941])\n",
      "tensor([0.6324, 0.5570, 0.5649])\n",
      "tensor([0.3999, 0.3103, 0.3191])\n",
      "tensor([-0.1749, -0.6089, -0.7441])\n",
      "tensor([0.8903, 0.6518, 0.4148])\n",
      "tensor([0.7927, 0.4249, 0.1721])\n",
      "tensor([0.3834, 0.3348, 0.2582])\n",
      "tensor([0.9418, 1.0110, 1.1107])\n",
      "tensor([0.8870, 1.0222, 1.2336])\n",
      "tensor([-0.4490, -0.4544, -0.5285])\n",
      "tensor([0.7998, 0.8238, 0.8177])\n",
      "tensor([0.6398, 0.6787, 0.6687])\n",
      "tensor([-0.3760, -0.5341, -0.9481])\n",
      "tensor([0.9803, 0.8326, 0.6035])\n",
      "tensor([0.9609, 0.6932, 0.3642])\n",
      "tensor([-0.3450, -0.5095, -0.4197])\n",
      "tensor([0.9157, 0.9703, 0.8615])\n",
      "tensor([0.8385, 0.9415, 0.7422])\n",
      "tensor([0.0296, 0.3207, 0.9795])\n",
      "tensor([1.0768, 1.2390, 1.2343])\n",
      "tensor([1.1596, 1.5352, 1.5236])\n",
      "tensor([-0.0062,  0.0010,  0.0648])\n",
      "tensor([0.6300, 0.7140, 0.8418])\n",
      "tensor([0.3969, 0.5098, 0.7087])\n",
      "tensor([-1.1209,  0.2698,  1.0304])\n",
      "tensor([0.3876, 0.4334, 0.5912])\n",
      "tensor([0.1502, 0.1878, 0.3495])\n",
      "tensor([-0.0493, -0.0025,  0.1611])\n",
      "tensor([0.7023, 0.8354, 0.9727])\n",
      "tensor([0.4933, 0.6979, 0.9461])\n",
      "tensor([ 0.5958,  0.4486, -0.2611])\n",
      "tensor([0.8835, 0.8224, 0.3837])\n",
      "tensor([0.7806, 0.6763, 0.1472])\n",
      "tensor([-0.4852, -0.3628, -0.4037])\n",
      "tensor([1.1199, 1.1647, 1.1472])\n",
      "tensor([1.2541, 1.3565, 1.3161])\n",
      "tensor([-0.6220, -0.3160, -0.2728])\n",
      "tensor([1.1992, 1.1401, 0.9951])\n",
      "tensor([1.4380, 1.2999, 0.9902])\n",
      "tensor([-0.4032, -0.4220, -0.6253])\n",
      "tensor([1.1721, 1.1749, 1.0398])\n",
      "tensor([1.3737, 1.3804, 1.0812])\n",
      "tensor([0.2650, 0.0064, 0.5680])\n",
      "tensor([0.9056, 1.1354, 0.6768])\n",
      "tensor([0.8202, 1.2891, 0.4580])\n",
      "tensor([-0.7030, -0.6357, -0.7820])\n",
      "tensor([0.6830, 0.5935, 0.4630])\n",
      "tensor([0.4665, 0.3522, 0.2144])\n",
      "tensor([-0.5219, -0.5996, -0.6257])\n",
      "tensor([0.6198, 0.6619, 0.5889])\n",
      "tensor([0.3841, 0.4381, 0.3468])\n",
      "tensor([ 0.0713, -0.1418, -0.3803])\n",
      "tensor([0.5539, 0.6329, 0.6730])\n",
      "tensor([0.3068, 0.4006, 0.4530])\n",
      "tensor([-0.7313, -0.2618, -0.0722])\n",
      "tensor([0.5611, 0.4913, 0.5770])\n",
      "tensor([0.3148, 0.2414, 0.3329])\n",
      "tensor([0.3561, 0.1226, 0.0329])\n",
      "tensor([1.0000, 1.0355, 1.1013])\n",
      "tensor([1.0000, 1.0722, 1.2128])\n",
      "tensor([-0.0161,  0.0435,  0.2659])\n",
      "tensor([0.9755, 0.9596, 0.8946])\n",
      "tensor([0.9517, 0.9209, 0.8004])\n",
      "tensor([0.0650, 0.0867, 0.1806])\n",
      "tensor([0.6533, 0.6990, 0.6522])\n",
      "tensor([0.4269, 0.4886, 0.4254])\n",
      "tensor([0.5210, 0.8974, 1.3318])\n",
      "tensor([1.2884, 0.8295, 0.4323])\n",
      "tensor([1.6601, 0.6881, 0.1869])\n",
      "tensor([ 0.3329, -0.0426, -0.2347])\n",
      "tensor([0.9874, 0.8867, 0.7662])\n",
      "tensor([0.9749, 0.7862, 0.5870])\n",
      "tensor([-0.2226, -0.0900, -0.0553])\n",
      "tensor([1.0963, 0.9787, 0.8056])\n",
      "tensor([1.2019, 0.9578, 0.6490])\n",
      "tensor([-0.5083, -0.9149, -1.0782])\n",
      "tensor([0.6821, 0.6299, 0.4362])\n",
      "tensor([0.4653, 0.3968, 0.1902])\n",
      "tensor([0.9400, 0.6894, 0.3926])\n",
      "tensor([0.8032, 0.9464, 0.9869])\n",
      "tensor([0.6452, 0.8957, 0.9739])\n",
      "tensor([ 0.1213, -0.0168,  0.0055])\n",
      "tensor([0.7080, 0.6913, 0.6503])\n",
      "tensor([0.5012, 0.4778, 0.4229])\n",
      "tensor([-0.7469, -0.5446, -0.5700])\n",
      "tensor([1.0742, 0.9942, 0.7767])\n",
      "tensor([1.1538, 0.9883, 0.6033])\n",
      "tensor([-0.0080, -0.0430, -0.1248])\n",
      "tensor([1.1090, 1.1195, 0.8385])\n",
      "tensor([1.2298, 1.2533, 0.7030])\n",
      "tensor([-0.7061, -0.5585, -0.1404])\n",
      "tensor([1.0711, 1.0636, 1.0244])\n",
      "tensor([1.1473, 1.1312, 1.0494])\n",
      "tensor([-0.2493, -0.0671, -0.1752])\n",
      "tensor([1.0143, 0.7789, 0.9855])\n",
      "tensor([1.0289, 0.6067, 0.9712])\n",
      "tensor([-0.7796, -0.2445,  0.4999])\n",
      "tensor([0.4704, 0.4090, 0.5194])\n",
      "tensor([0.2213, 0.1672, 0.2698])\n",
      "tensor([-0.0518,  0.2408, -0.2426])\n",
      "tensor([0.6330, 0.7304, 0.6275])\n",
      "tensor([0.4007, 0.5335, 0.3937])\n",
      "tensor([-0.1957, -0.3245, -0.3723])\n",
      "tensor([0.7874, 0.7214, 0.5794])\n",
      "tensor([0.6201, 0.5204, 0.3357])\n",
      "tensor([ 0.0047,  0.1627, -0.8092])\n",
      "tensor([0.8638, 0.7539, 0.5168])\n",
      "tensor([0.7461, 0.5684, 0.2671])\n",
      "tensor([-0.1367, -0.1200,  0.0309])\n",
      "tensor([0.7509, 0.7432, 0.6682])\n",
      "tensor([0.5639, 0.5523, 0.4465])\n",
      "tensor([-0.2127, -0.1065,  0.0591])\n",
      "tensor([0.5772, 0.5758, 0.5894])\n",
      "tensor([0.3331, 0.3316, 0.3474])\n",
      "tensor([0.2304, 0.1354, 0.1599])\n",
      "tensor([1.0112, 1.0469, 1.0118])\n",
      "tensor([1.0225, 1.0961, 1.0237])\n",
      "tensor([-0.3218,  0.0511, -0.0003])\n",
      "tensor([1.1894, 1.0389, 1.0294])\n",
      "tensor([1.4146, 1.0794, 1.0597])\n",
      "tensor([0.2619, 0.3692, 0.3678])\n",
      "tensor([0.8862, 0.8516, 0.8028])\n",
      "tensor([0.7853, 0.7252, 0.6445])\n",
      "tensor([0.4262, 1.2100, 1.3113])\n",
      "tensor([0.6097, 0.7760, 0.8176])\n",
      "tensor([0.3717, 0.6022, 0.6685])\n",
      "tensor([-0.5289, -0.4992, -0.2049])\n",
      "tensor([0.9052, 0.8774, 0.7628])\n",
      "tensor([0.8193, 0.7698, 0.5819])\n",
      "tensor([-0.1039,  0.2705,  0.5732])\n",
      "tensor([1.1213, 0.9855, 0.8675])\n",
      "tensor([1.2574, 0.9712, 0.7526])\n",
      "tensor([-0.9027, -0.8557, -0.3582])\n",
      "tensor([0.8436, 0.5687, 0.8741])\n",
      "tensor([0.7117, 0.3234, 0.7640])\n",
      "tensor([0.9236, 0.9753, 1.0441])\n",
      "tensor([1.2200, 1.2380, 1.1524])\n",
      "tensor([1.4883, 1.5328, 1.3281])\n",
      "tensor([0.2755, 0.6462, 0.9707])\n",
      "tensor([0.8934, 0.9688, 0.9120])\n",
      "tensor([0.7982, 0.9385, 0.8317])\n",
      "tensor([ 0.0028, -0.0533, -0.0527])\n",
      "tensor([0.9186, 0.9950, 0.9984])\n",
      "tensor([0.8439, 0.9901, 0.9969])\n",
      "tensor([0.5735, 0.3012, 0.0762])\n",
      "tensor([0.9233, 0.9157, 1.0486])\n",
      "tensor([0.8524, 0.8385, 1.0995])\n",
      "tensor([0.5250, 0.1866, 0.0415])\n",
      "tensor([0.6026, 0.5624, 0.4958])\n",
      "tensor([0.3632, 0.3163, 0.2458])\n",
      "tensor([-0.3317, -0.5585, -0.4166])\n",
      "tensor([0.8822, 0.8761, 0.7411])\n",
      "tensor([0.7783, 0.7676, 0.5492])\n",
      "tensor([-0.5543, -0.7617, -0.7207])\n",
      "tensor([0.7527, 0.6140, 0.5039])\n",
      "tensor([0.5665, 0.3770, 0.2539])\n",
      "tensor([-0.8589, -0.8394, -1.1772])\n",
      "tensor([0.5367, 0.4100, 0.1881])\n",
      "tensor([0.2881, 0.1681, 0.0354])\n",
      "tensor([ 0.2794, -0.0425, -0.1631])\n",
      "tensor([0.9671, 0.8227, 0.5325])\n",
      "tensor([0.9353, 0.6768, 0.2835])\n",
      "tensor([ 0.6591,  0.1944, -0.3669])\n",
      "tensor([0.8051, 0.9236, 0.7476])\n",
      "tensor([0.6481, 0.8531, 0.5590])\n",
      "tensor([-0.1204, -0.0133, -0.0500])\n",
      "tensor([1.0430, 1.0345, 1.0743])\n",
      "tensor([1.0879, 1.0702, 1.1541])\n",
      "tensor([0.6647, 0.4315, 0.0736])\n",
      "tensor([0.8125, 0.8412, 0.9511])\n",
      "tensor([0.6601, 0.7077, 0.9046])\n",
      "tensor([1.2744, 1.2742, 1.2129])\n",
      "tensor([0.8322, 0.9137, 0.9283])\n",
      "tensor([0.6925, 0.8349, 0.8617])\n",
      "tensor([-0.4259, -0.4644, -0.3338])\n",
      "tensor([0.3910, 0.3259, 0.2737])\n",
      "tensor([0.1529, 0.1062, 0.0749])\n",
      "tensor([-0.7323, -0.9179, -0.7590])\n",
      "tensor([0.7275, 0.7042, 0.6190])\n",
      "tensor([0.5293, 0.4958, 0.3832])\n",
      "tensor([-0.0054,  0.0236, -0.0194])\n",
      "tensor([1.1612, 1.2358, 1.1955])\n",
      "tensor([1.3483, 1.5273, 1.4292])\n",
      "tensor([-0.0035,  0.1404,  0.2688])\n",
      "tensor([0.5736, 0.5249, 0.4713])\n",
      "tensor([0.3290, 0.2755, 0.2221])\n",
      "tensor([-0.0314,  0.3323,  0.5589])\n",
      "tensor([1.2449, 1.2890, 1.1038])\n",
      "tensor([1.5499, 1.6616, 1.2183])\n",
      "tensor([0.1689, 0.1285, 0.2513])\n",
      "tensor([0.9779, 1.1817, 1.1125])\n",
      "tensor([0.9563, 1.3963, 1.2377])\n",
      "tensor([ 0.7338, -0.0521, -0.9359])\n",
      "tensor([0.9838, 0.6853, 0.7927])\n",
      "tensor([0.9679, 0.4697, 0.6283])\n",
      "tensor([ 0.5235, -0.1337, -0.1577])\n",
      "tensor([0.8164, 1.1701, 1.0731])\n",
      "tensor([0.6665, 1.3691, 1.1516])\n",
      "tensor([0.3382, 0.3898, 0.3160])\n",
      "tensor([0.9715, 0.9912, 1.0350])\n",
      "tensor([0.9437, 0.9825, 1.0712])\n",
      "tensor([0.6288, 0.2865, 0.2537])\n",
      "tensor([0.7613, 0.9595, 0.9200])\n",
      "tensor([0.5795, 0.9206, 0.8463])\n",
      "tensor([0.1363, 0.2379, 0.0680])\n",
      "tensor([0.7301, 0.6134, 0.6414])\n",
      "tensor([0.5331, 0.3762, 0.4114])\n",
      "tensor([-0.3281, -0.2954, -0.1398])\n",
      "tensor([0.8356, 0.8447, 0.8219])\n",
      "tensor([0.6982, 0.7134, 0.6754])\n",
      "tensor([0.2126, 0.4540, 0.6691])\n",
      "tensor([1.0735, 1.0337, 0.9666])\n",
      "tensor([1.1524, 1.0685, 0.9343])\n",
      "tensor([ 0.1739, -0.1392, -0.2604])\n",
      "tensor([0.7824, 0.7523, 0.6578])\n",
      "tensor([0.6121, 0.5659, 0.4327])\n",
      "tensor([ 0.0040, -0.0780,  0.0658])\n",
      "tensor([0.9172, 0.9198, 0.8772])\n",
      "tensor([0.8413, 0.8461, 0.7695])\n",
      "tensor([0.1243, 0.0839, 0.0784])\n",
      "tensor([1.2300, 1.1839, 1.0038])\n",
      "tensor([1.5128, 1.4016, 1.0076])\n",
      "tensor([-0.2503, -0.0856, -0.5869])\n",
      "tensor([0.4992, 0.6199, 0.5637])\n",
      "tensor([0.2492, 0.3843, 0.3177])\n",
      "tensor([-0.4086, -0.4639, -0.2149])\n",
      "tensor([0.9611, 0.9628, 0.8624])\n",
      "tensor([0.9236, 0.9269, 0.7437])\n",
      "tensor([-0.0080,  0.1072,  0.2126])\n",
      "tensor([0.5523, 0.5331, 0.9039])\n",
      "tensor([0.3051, 0.2841, 0.8170])\n",
      "tensor([0.3212, 0.2474, 0.3738])\n",
      "tensor([1.1288, 1.2000, 1.1216])\n",
      "tensor([1.2743, 1.4399, 1.2581])\n",
      "tensor([-0.2131,  0.0312, -0.5873])\n",
      "tensor([0.6996, 0.5609, 0.6303])\n",
      "tensor([0.4894, 0.3146, 0.3973])\n",
      "tensor([-0.3532, -0.4989, -0.4483])\n",
      "tensor([0.9583, 0.9598, 0.8171])\n",
      "tensor([0.9183, 0.9212, 0.6677])\n",
      "tensor([-0.0960, -0.0282,  0.1349])\n",
      "tensor([0.9503, 0.9734, 0.9501])\n",
      "tensor([0.9031, 0.9475, 0.9026])\n",
      "tensor([-0.7940, -0.6394, -0.7768])\n",
      "tensor([0.4597, 0.3899, 0.3001])\n",
      "tensor([0.2113, 0.1520, 0.0900])\n",
      "tensor([0.8342, 0.8846, 0.9597])\n",
      "tensor([0.4806, 0.4877, 0.4540])\n",
      "tensor([0.2309, 0.2378, 0.2061])\n",
      "tensor([-0.0548,  0.0573, -0.3586])\n",
      "tensor([0.5040, 0.5741, 0.4191])\n",
      "tensor([0.2540, 0.3296, 0.1756])\n",
      "tensor([0.3398, 0.1051, 0.1950])\n",
      "tensor([0.9469, 0.8768, 0.7721])\n",
      "tensor([0.8966, 0.7687, 0.5961])\n",
      "tensor([-0.2623, -0.3931, -0.5153])\n",
      "tensor([0.7501, 0.7260, 0.4514])\n",
      "tensor([0.5626, 0.5271, 0.2037])\n",
      "tensor([ 0.5357,  0.0014, -0.1167])\n",
      "tensor([0.9279, 0.9841, 0.8173])\n",
      "tensor([0.8610, 0.9685, 0.6680])\n",
      "tensor([-0.6645, -0.7771, -0.6300])\n",
      "tensor([0.6525, 0.6597, 0.6901])\n",
      "tensor([0.4258, 0.4352, 0.4762])\n",
      "tensor([1.1965, 1.3343, 1.4336])\n",
      "tensor([1.0267, 0.9980, 0.8448])\n",
      "tensor([1.0542, 0.9960, 0.7137])\n",
      "tensor([0.6219, 0.6727, 0.8206])\n",
      "tensor([1.5245, 1.5477, 1.3717])\n",
      "tensor([2.3242, 2.3955, 1.8817])\n",
      "tensor([0.0793, 0.3302, 0.1606])\n",
      "tensor([1.0638, 1.1230, 1.1769])\n",
      "tensor([1.1318, 1.2612, 1.3851])\n",
      "tensor([-0.5975, -0.5068, -0.3445])\n",
      "tensor([0.6566, 0.7022, 0.6712])\n",
      "tensor([0.4311, 0.4932, 0.4505])\n",
      "tensor([ 0.1853, -0.1195, -0.2020])\n",
      "tensor([0.9130, 0.8502, 0.7596])\n",
      "tensor([0.8336, 0.7228, 0.5770])\n",
      "tensor([-0.3960, -0.3294, -0.5850])\n",
      "tensor([0.9114, 0.8486, 0.8414])\n",
      "tensor([0.8306, 0.7202, 0.7080])\n",
      "tensor([-0.7096, -0.9004, -0.7158])\n",
      "tensor([0.5652, 0.4850, 0.2424])\n",
      "tensor([0.3195, 0.2352, 0.0588])\n",
      "tensor([-0.1662, -0.0321,  0.0756])\n",
      "tensor([0.9603, 0.8186, 0.9798])\n",
      "tensor([0.9222, 0.6702, 0.9601])\n",
      "tensor([0.5262, 0.5982, 0.7176])\n",
      "tensor([1.3216, 1.3260, 1.2485])\n",
      "tensor([1.7465, 1.7584, 1.5586])\n",
      "tensor([-0.7710, -0.7291, -0.3904])\n",
      "tensor([0.8809, 0.8789, 0.7685])\n",
      "tensor([0.7760, 0.7725, 0.5906])\n",
      "tensor([0.4455, 0.4046, 0.2990])\n",
      "tensor([0.5051, 0.5173, 0.5885])\n",
      "tensor([0.2551, 0.2676, 0.3463])\n",
      "tensor([ 0.1229, -0.6188, -0.5357])\n",
      "tensor([0.6744, 1.1135, 0.8432])\n",
      "tensor([0.4548, 1.2399, 0.7110])\n",
      "tensor([0.4022, 0.1900, 0.2416])\n",
      "tensor([1.0819, 1.1838, 1.1111])\n",
      "tensor([1.1705, 1.4014, 1.2344])\n",
      "tensor([0.2960, 0.2163, 0.2476])\n",
      "tensor([0.5792, 0.5518, 0.4975])\n",
      "tensor([0.3355, 0.3045, 0.2475])\n",
      "tensor([1.2224, 1.2785, 1.3264])\n",
      "tensor([1.1455, 1.1625, 1.0821])\n",
      "tensor([1.3121, 1.3514, 1.1710])\n",
      "tensor([-0.5066, -0.5136, -0.9703])\n",
      "tensor([0.6862, 0.6553, 0.3693])\n",
      "tensor([0.4709, 0.4295, 0.1364])\n",
      "tensor([ 0.2842, -0.0030, -0.2613])\n",
      "tensor([0.7404, 0.7775, 0.8087])\n",
      "tensor([0.5481, 0.6045, 0.6540])\n",
      "tensor([1.1053, 0.7664, 0.5084])\n",
      "tensor([0.6081, 0.8832, 1.0418])\n",
      "tensor([0.3697, 0.7800, 1.0854])\n",
      "tensor([ 0.1698,  0.1535, -0.1174])\n",
      "tensor([0.4162, 0.4016, 0.3496])\n",
      "tensor([0.1732, 0.1613, 0.1222])\n",
      "tensor([-0.5179, -0.5186, -0.2710])\n",
      "tensor([0.7068, 0.5940, 0.3895])\n",
      "tensor([0.4995, 0.3529, 0.1517])\n",
      "tensor([0.3189, 0.5166, 0.6242])\n",
      "tensor([0.9392, 0.9153, 0.8776])\n",
      "tensor([0.8822, 0.8379, 0.7702])\n",
      "tensor([-0.0696, -0.0573,  0.2024])\n",
      "tensor([0.9564, 1.1486, 1.1862])\n",
      "tensor([0.9147, 1.3193, 1.4071])\n",
      "tensor([ 0.1102, -0.0300, -0.1970])\n",
      "tensor([1.0426, 0.8612, 0.7674])\n",
      "tensor([1.0871, 0.7417, 0.5888])\n",
      "tensor([-0.3303, -0.0659,  0.2018])\n",
      "tensor([0.7395, 0.7826, 0.7228])\n",
      "tensor([0.5469, 0.6124, 0.5225])\n",
      "tensor([0.8945, 0.7438, 0.5406])\n",
      "tensor([1.0208, 1.1613, 1.3037])\n",
      "tensor([1.0421, 1.3486, 1.6998])\n",
      "tensor([-1.1263, -1.1001, -0.9182])\n",
      "tensor([0.4251, 0.4040, 0.3914])\n",
      "tensor([0.1807, 0.1633, 0.1532])\n",
      "tensor([-0.2509,  0.3850,  1.2163])\n",
      "tensor([0.9827, 1.0382, 0.8134])\n",
      "tensor([0.9658, 1.0778, 0.6616])\n",
      "tensor([ 0.3039, -0.0588, -0.2025])\n",
      "tensor([0.7363, 0.9228, 0.9898])\n",
      "tensor([0.5422, 0.8515, 0.9797])\n",
      "tensor([-0.3049, -0.3594, -0.7658])\n",
      "tensor([1.2643, 1.1928, 1.0169])\n",
      "tensor([1.5985, 1.4228, 1.0342])\n",
      "tensor([0.7532, 0.6802, 0.5267])\n",
      "tensor([0.9780, 1.0827, 1.1509])\n",
      "tensor([0.9565, 1.1722, 1.3247])\n",
      "tensor([-0.6985, -0.8969, -0.8687])\n",
      "tensor([1.3700, 1.2333, 0.9647])\n",
      "tensor([1.8768, 1.5210, 0.9306])\n",
      "tensor([0.2329, 0.2896, 0.1344])\n",
      "tensor([0.8983, 1.0077, 1.1234])\n",
      "tensor([0.8069, 1.0155, 1.2621])\n",
      "tensor([0.2585, 0.3075, 0.3969])\n",
      "tensor([0.8500, 0.8747, 0.8717])\n",
      "tensor([0.7224, 0.7652, 0.7599])\n",
      "tensor([-0.0909,  0.1395,  0.0657])\n",
      "tensor([0.4342, 0.2936, 0.3101])\n",
      "tensor([0.1885, 0.0862, 0.0961])\n",
      "tensor([-0.5714, -0.7068, -0.6595])\n",
      "tensor([0.8905, 0.8716, 0.6948])\n",
      "tensor([0.7929, 0.7597, 0.4828])\n",
      "tensor([0.5265, 0.3170, 0.0783])\n",
      "tensor([0.7224, 0.6897, 0.6783])\n",
      "tensor([0.5219, 0.4757, 0.4601])\n",
      "tensor([0.4658, 0.5911, 0.9752])\n",
      "tensor([0.5772, 0.5266, 0.7955])\n",
      "tensor([0.3332, 0.2773, 0.6328])\n",
      "tensor([-1.0802, -0.9923, -0.3480])\n",
      "tensor([0.5946, 0.4683, 0.4123])\n",
      "tensor([0.3535, 0.2193, 0.1700])\n",
      "tensor([-0.4794, -0.6069, -0.3500])\n",
      "tensor([0.7419, 0.6629, 0.6875])\n",
      "tensor([0.5504, 0.4395, 0.4727])\n",
      "tensor([-0.4882, -0.5240, -0.4272])\n",
      "tensor([0.7771, 0.7769, 0.7910])\n",
      "tensor([0.6038, 0.6036, 0.6257])\n",
      "tensor([0.5091, 0.5938, 0.1037])\n",
      "tensor([0.8796, 0.9208, 0.6764])\n",
      "tensor([0.7736, 0.8479, 0.4575])\n",
      "tensor([0.3055, 0.3042, 0.3876])\n",
      "tensor([0.8722, 0.9374, 0.9345])\n",
      "tensor([0.7608, 0.8787, 0.8734])\n",
      "tensor([-0.4595, -0.5075, -0.4224])\n",
      "tensor([1.0201, 1.0119, 0.9156])\n",
      "tensor([1.0407, 1.0240, 0.8384])\n",
      "tensor([-0.8972, -0.9365, -1.0062])\n",
      "tensor([0.7324, 0.6979, 0.4892])\n",
      "tensor([0.5364, 0.4871, 0.2393])\n",
      "tensor([-0.5916, -0.5060, -0.1255])\n",
      "tensor([0.6465, 0.8140, 1.1049])\n",
      "tensor([0.4180, 0.6627, 1.2207])\n",
      "tensor([0.9225, 0.9861, 1.0820])\n",
      "tensor([1.3430, 1.3496, 1.2350])\n",
      "tensor([1.8035, 1.8215, 1.5253])\n",
      "tensor([0.7040, 0.7522, 0.8710])\n",
      "tensor([1.0259, 1.0501, 0.9535])\n",
      "tensor([1.0526, 1.1027, 0.9092])\n",
      "tensor([0.1168, 0.3599, 0.4945])\n",
      "tensor([1.1288, 1.1062, 1.0464])\n",
      "tensor([1.2742, 1.2237, 1.0949])\n",
      "tensor([-0.5867, -0.7683, -0.8018])\n",
      "tensor([0.5646, 0.5316, 0.3998])\n",
      "tensor([0.3188, 0.2826, 0.1598])\n",
      "tensor([0.0487, 0.7035, 1.3961])\n",
      "tensor([0.7825, 1.0655, 1.2776])\n",
      "tensor([0.6123, 1.1353, 1.6323])\n",
      "tensor([ 0.3917,  0.1218, -0.0111])\n",
      "tensor([0.6022, 0.6356, 0.6353])\n",
      "tensor([0.3626, 0.4040, 0.4037])\n",
      "tensor([0.2973, 0.2652, 0.1451])\n",
      "tensor([0.2280, 0.2712, 0.3091])\n",
      "tensor([0.0520, 0.0736, 0.0955])\n",
      "tensor([-0.3372,  0.0153, -0.5506])\n",
      "tensor([0.8980, 0.9520, 0.6955])\n",
      "tensor([0.8065, 0.9064, 0.4837])\n",
      "tensor([-0.2824, -0.4587, -0.3738])\n",
      "tensor([0.8389, 0.9406, 0.8899])\n",
      "tensor([0.7038, 0.8847, 0.7919])\n",
      "tensor([-0.3736,  0.1642,  0.6647])\n",
      "tensor([0.4183, 0.4069, 0.3815])\n",
      "tensor([0.1750, 0.1655, 0.1455])\n",
      "tensor([-0.3335, -0.7762, -0.6244])\n",
      "tensor([0.9105, 0.7319, 0.7356])\n",
      "tensor([0.8291, 0.5356, 0.5411])\n",
      "tensor([0.4389, 0.6806, 0.4952])\n",
      "tensor([0.7919, 0.6891, 0.7231])\n",
      "tensor([0.6271, 0.4749, 0.5229])\n",
      "tensor([-0.4097, -0.0753, -0.2218])\n",
      "tensor([0.5348, 0.4711, 0.4599])\n",
      "tensor([0.2860, 0.2219, 0.2116])\n",
      "tensor([-0.3228, -0.4249, -0.6271])\n",
      "tensor([0.4817, 0.4602, 0.4180])\n",
      "tensor([0.2321, 0.2118, 0.1748])\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'global_step_train' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Explorer\\Dokumente\\Bachelor\\git\\activation-ba\\code\\cifar.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 66>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Explorer/Dokumente/Bachelor/git/activation-ba/code/cifar.ipynb#ch0000012?line=65'>66</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Explorer/Dokumente/Bachelor/git/activation-ba/code/cifar.ipynb#ch0000012?line=67'>68</a>\u001b[0m     \u001b[39mprint\u001b[39m(epoch)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Explorer/Dokumente/Bachelor/git/activation-ba/code/cifar.ipynb#ch0000012?line=68'>69</a>\u001b[0m     train()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Explorer/Dokumente/Bachelor/git/activation-ba/code/cifar.ipynb#ch0000012?line=70'>71</a>\u001b[0m     test()\n",
      "\u001b[1;32me:\\Explorer\\Dokumente\\Bachelor\\git\\activation-ba\\code\\cifar.ipynb Cell 13'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Explorer/Dokumente/Bachelor/git/activation-ba/code/cifar.ipynb#ch0000012?line=39'>40</a>\u001b[0m         writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m\"\u001b[39m\u001b[39mTraining loss\u001b[39m\u001b[39m\"\u001b[39m, loss, global_step\u001b[39m=\u001b[39mglobal_step_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Explorer/Dokumente/Bachelor/git/activation-ba/code/cifar.ipynb#ch0000012?line=40'>41</a>\u001b[0m         writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m\"\u001b[39m\u001b[39mTraining Accuracy\u001b[39m\u001b[39m\"\u001b[39m, acc, global_step\u001b[39m=\u001b[39mglobal_step_train)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Explorer/Dokumente/Bachelor/git/activation-ba/code/cifar.ipynb#ch0000012?line=41'>42</a>\u001b[0m     global_step_train \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Explorer/Dokumente/Bachelor/git/activation-ba/code/cifar.ipynb#ch0000012?line=42'>43</a>\u001b[0m mean_acc \u001b[39m=\u001b[39m acc \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(train_l\u001b[39m.\u001b[39mdataset)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Explorer/Dokumente/Bachelor/git/activation-ba/code/cifar.ipynb#ch0000012?line=43'>44</a>\u001b[0m mean_loss \u001b[39m=\u001b[39m loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(train_l\u001b[39m.\u001b[39mdataset)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'global_step_train' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "x = current_time.replace(':','_')\n",
    "\n",
    "\n",
    "#device setup \n",
    "device =  'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda:0':\n",
    "    print('running on gpu')\n",
    "\n",
    "writer = SummaryWriter()\n",
    "#Params 0.1 0.03 0.001 0.0003\n",
    "lr = 0.001\n",
    "epochs = 200\n",
    "batch_size = 128\n",
    "\n",
    "model = CNN_CIFAR()\n",
    "optimizer = optim.Adam(model.parameters(),lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.to(device)\n",
    "writer = SummaryWriter(f'/runs/cifar_conv64_32_1fc_lr0.001_kernel3_5s1')\n",
    "#Data\n",
    "dat = CIFAR10()\n",
    "\n",
    "#dataset\n",
    "ds = Cifar10Dataset\n",
    "\n",
    "\n",
    "#get data for dl\n",
    "X_train,y_train = dat.get_data('train')\n",
    "X_val,y_val = dat.get_data('val')\n",
    "train = ds(X_train,y_train)\n",
    "test = ds(X_val,y_val)\n",
    "\n",
    "trains = torch.utils.data.DataLoader(dataset=train,batch_size=batch_size,shuffle=False)\n",
    "tests = torch.utils.data.DataLoader(dataset=test,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "def evaluate(X, y, train=False):\n",
    "        if train:\n",
    "            model.zero_grad()\n",
    "\n",
    "        scores = model(X)\n",
    "        matches = [torch.argmax(i) == torch.argmax(j) for i,j in zip(scores,y)]\n",
    "        acc = matches.count(True)/len(matches)\n",
    "\n",
    "        loss = criterion(scores,y)\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        return acc,loss.item()\n",
    "\n",
    "def train(epoch,trainss):\n",
    "        model.train()\n",
    "        acc = 0.0\n",
    "        loss = 0.0\n",
    "\n",
    "        for idx,(data,targets) in enumerate(trainss):\n",
    "            \n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "            \n",
    "            accs, losses = evaluate(data,targets,train=True)\n",
    "            loss += losses * data.size(0)\n",
    "            acc += accs * data.size(0)\n",
    "        \n",
    "        mean_acc = acc / len(trainss.dataset)\n",
    "        mean_loss = loss / len(trainss.dataset)\n",
    "        writer.add_scalar('Mean Accuracy Train',mean_acc,epoch)\n",
    "        writer.add_scalar('Mean Loss Train',mean_loss,epoch)\n",
    "        return mean_acc, mean_loss\n",
    "def test(epoch,testss):\n",
    "        acc = 0.0\n",
    "        loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for (data,targets) in testss:\n",
    "                data = data.to(device=device)\n",
    "                targets = targets.to(device=device)\n",
    "\n",
    "                accs, losses = evaluate(data,targets,train=False)\n",
    "                loss += losses * data.size(0)\n",
    "                acc += accs * data.size(0)\n",
    "        mean_acc = acc / len(testss.dataset)\n",
    "        mean_loss = loss / len(testss.dataset)\n",
    "        writer.add_scalar('Mean Accuracy Test',mean_acc,epoch)\n",
    "        writer.add_scalar('Mean Loss Test',mean_loss,epoch)\n",
    "        return mean_acc, mean_loss\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: [{epoch+1} / {epochs}]')\n",
    "    train_acc,train_loss = train(epoch,trains)\n",
    "\n",
    "    test_acc,test_loss = test(epoch,tests)\n",
    "    print(f'Test acc: {test_acc} Test loss: {test_loss} Train acc: {train_acc} Train loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c76f2bbdeea3b35e09f31260f1bf99570ebe30ad33776c3a9039c1ff1f2ebff"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
